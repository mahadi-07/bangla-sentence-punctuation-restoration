{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399cfaad",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241352be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492864c",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4b105",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791210a2",
   "metadata": {},
   "source": [
    "##### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94fe41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"hishab/hishab-pr-bn-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47cf0e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'source', 'score'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "57fec012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'source', 'score'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds[\"train\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f081ba8",
   "metadata": {},
   "source": [
    "##### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds[\"train\"]\n",
    "print(df)\n",
    "# print(f\"Features: {df.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, features in df.features.items():\n",
    "    print(f\"{name}: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_conversation_len = {len(item) for item in df[\"conversations\"]}\n",
    "print(unique_conversation_len)\n",
    "print({item[0]['from'] for item in df[\"conversations\"]})\n",
    "print({item[1]['from'] for item in df[\"conversations\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77446ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print random 5 \"synthetic data\" example\n",
    "examples = df.filter(lambda x: x[\"source\"] == \"synthetic_data\")\n",
    "# print(examples.to_pandas()[:5])\n",
    "\n",
    "examples = [x for x in df if x[\"source\"] == \"synthetic_data\"][:5]\n",
    "for x in examples:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b949b9",
   "metadata": {},
   "source": [
    "##### Dropping the `score` column\n",
    "* Quality score ranging from 0.0 to 10.0. This randomly generated value is a byproduct of the dataset processing pipeline and is not specifically relevant to the punctuation restoration task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8373e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping \"score\" column\n",
    "# score: Quality score ranging from 0.0 to 10.0. This randomly generated value is a byproduct of the dataset processing pipeline and is not specifically relevant to the punctuation restoration task.\n",
    "\n",
    "if \"score\" in df.column_names:\n",
    "    df = df.remove_columns(column_names=\"score\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92136d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = list(df[\"score\"])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(scores)\n",
    "# plt.xlabel(\"Score\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Score Distribution\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# word_lens = [\n",
    "#     sum(len(turn[\"value\"].split()) for turn in conv)\n",
    "#     for conv in df[\"conversations\"]\n",
    "# ]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(word_lens)\n",
    "# plt.xlabel(\"Total Words per Conversation\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Conversation Length (Words)\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# human_conv_len = [\n",
    "#     len(conv[0][\"value\"].split())\n",
    "#     for conv in df[\"conversations\"]\n",
    "# ]\n",
    "\n",
    "# human_conv_len = np.array(human_conv_len)\n",
    "# human_conv_len = np.sort(human_conv_len)\n",
    "# print(human_conv_len)\n",
    "# human_conv_len.min(), human_conv_len.max(), human_conv_len.mean()\n",
    "\n",
    "\n",
    "# empty_human_indices = [\n",
    "#     i for i, conv in enumerate(df[\"conversations\"])\n",
    "#     if len(conv[0][\"value\"].split()) <= 0\n",
    "# ]\n",
    "\n",
    "# print(\"Number of empty human inputs:\", len(empty_human_indices))\n",
    "# print(\"Indices of empty human inputs:\", empty_human_indices)\n",
    "\n",
    "# print(df[empty_human_indices[:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c27a39",
   "metadata": {},
   "source": [
    "##### Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7bd5826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bd_news_data', 'synthetic_data', 'hqtts_data', 'non_verbal_data']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique source\n",
    "df.unique(\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2edb63c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'synthetic_data': 1110,\n",
       "         'bd_news_data': 833,\n",
       "         'hqtts_data': 50,\n",
       "         'non_verbal_data': 7})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row counts from each source\n",
    "Counter(df[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0d475175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human',\n",
       "  'value': 'বাংলাদেশ প্রতিনিধিদলের একটি সূত্র অবশ্য প্রথম আলোকে জানায় তিস্তা নিয়ে কিছু বলার সময় এখনো আসেনি এ নিয়ে তাড়াহুড়োও নেই ভারতের আশ্বাসে আমরা সন্তুষ্ট মমতা বন্দ্যোপাধ্যায়ের ওপরেও আমাদের ভরসা আছে আমরা জানি ঠিক সময়েই এই বোঝাপড়া হয়ে যাবে চার দেশীয় যান চলাচল চুক্তি বিবিআইএন নিয়েও দুই পররাষ্ট্রসচিব বিস্তারিত আলোচনা করেছেন'},\n",
       " {'from': 'gpt',\n",
       "  'value': 'বাংলাদেশ প্রতিনিধিদলের একটি সূত্র অবশ্য প্রথম আলোকে জানায়, তিস্তা নিয়ে কিছু বলার সময় এখনো আসেনি। এ নিয়ে তাড়াহুড়োও নেই। ভারতের আশ্বাসে আমরা সন্তুষ্ট। মমতা বন্দ্যোপাধ্যায়ের ওপরেও আমাদের ভরসা আছে। আমরা জানি ঠিক সময়েই এই বোঝাপড়া হয়ে যাবে, চার দেশীয় যান চলাচল চুক্তি বিবিআইএন নিয়েও দুই পররাষ্ট্রসচিব বিস্তারিত আলোচনা করেছেন।'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row's \"conversation\" column\n",
    "df[\"conversations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b803e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entry in each conversation\n",
    "# must be equal to 2\n",
    "assert all(len(conv) == 2 for conv in df[\"conversations\"]), \"Must be exactly two entry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d8675bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt', 'human'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique conversation participants\n",
    "unique_participants = {\n",
    "    participant['from'] for conv in df[\"conversations\"]\n",
    "    for participant in conv\n",
    "}\n",
    "assert len(unique_participants) == 2, \"Must be only two differnt participants\"\n",
    "unique_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9851261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), np.int64(943), np.float64(138.56775))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min, max, average conversation character length\n",
    "conv_len = [\n",
    "    len(entry[\"value\"]) for conv in df[\"conversations\"] for entry in conv\n",
    "]\n",
    "assert len(conv_len) == 4000, \"Should be equal 4000\"\n",
    "\n",
    "conv_len = np.array(conv_len)\n",
    "conv_len.min(), conv_len.max(), conv_len.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "171b03fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), np.int64(135), np.float64(22.642))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min, max, average conversation word length\n",
    "conv_word_len = [len(entry[\"value\"].split()) for conv in df[\"conversations\"] for entry in conv]\n",
    "conv_word_len = np.array(conv_word_len)\n",
    "conv_word_len.min(), conv_word_len.max(), conv_word_len.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6a55b74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), np.int64(34), np.float64(4.1845))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimum, maximum, average times puncuation added to a sentence\n",
    "punc_added_counts = [\n",
    "    len(conv[1 ][\"value\"]) - len(conv[0][\"value\"]) for conv in df[\"conversations\"]\n",
    "]\n",
    "\n",
    "punc_added_counts = np.array(punc_added_counts)\n",
    "punc_added_counts.min(), punc_added_counts.max(), punc_added_counts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5580bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",।।।।,।\n"
     ]
    }
   ],
   "source": [
    "# print punc added to a sentence\n",
    "def get_punc_added(without_punc_senc, with_punc_senc):\n",
    "    \"\"\"\n",
    "    Returns a string of characters in `second` that do not match `first`,\n",
    "    filtered to only include punctuation.\n",
    "    \"\"\"\n",
    "    punc_added = \"\"\n",
    "    i = 0\n",
    "    for ch in with_punc_senc:\n",
    "        if i < len(without_punc_senc) and ch == without_punc_senc[i]:\n",
    "            i = i + 1\n",
    "        else:\n",
    "            punc_added += ch\n",
    "    return punc_added\n",
    "\n",
    "added = get_punc_added(\n",
    "    df[\"conversations\"][0][0][\"value\"],\n",
    "    df[\"conversations\"][0][1][\"value\"]\n",
    ")\n",
    "print(added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "afe49e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '!',\n",
       " '\"',\n",
       " '%',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '?',\n",
       " '[',\n",
       " ']',\n",
       " '।',\n",
       " '—',\n",
       " '‘',\n",
       " '’'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distict punc list added\n",
    "punc_list = [get_punc_added(conv[0][\"value\"], conv[1][\"value\"]) for conv in df[\"conversations\"]]\n",
    "distinct_puncs = set(\"\".join(punc_list))\n",
    "distinct_puncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "afb235b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'।': 3477,\n",
       "         ',': 2543,\n",
       "         '?': 1424,\n",
       "         '\"': 430,\n",
       "         '!': 246,\n",
       "         '-': 73,\n",
       "         ')': 50,\n",
       "         '(': 47,\n",
       "         \"'\": 29,\n",
       "         ' ': 23,\n",
       "         '%': 17,\n",
       "         '.': 5,\n",
       "         '‘': 1,\n",
       "         '’': 1,\n",
       "         '—': 1,\n",
       "         '[': 1,\n",
       "         ']': 1})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each punctuation occur\n",
    "punc_counts = Counter(\"\".join(punc_list))\n",
    "punc_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
