{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399cfaad",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241352be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492864c",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4b105",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791210a2",
   "metadata": {},
   "source": [
    "##### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94fe41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"hishab/hishab-pr-bn-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47cf0e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'source', 'score'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "57fec012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'source', 'score'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds[\"train\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f081ba8",
   "metadata": {},
   "source": [
    "##### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds[\"train\"]\n",
    "print(df)\n",
    "# print(f\"Features: {df.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, features in df.features.items():\n",
    "    print(f\"{name}: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_conversation_len = {len(item) for item in df[\"conversations\"]}\n",
    "print(unique_conversation_len)\n",
    "print({item[0]['from'] for item in df[\"conversations\"]})\n",
    "print({item[1]['from'] for item in df[\"conversations\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77446ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print random 5 \"synthetic data\" example\n",
    "examples = df.filter(lambda x: x[\"source\"] == \"synthetic_data\")\n",
    "# print(examples.to_pandas()[:5])\n",
    "\n",
    "examples = [x for x in df if x[\"source\"] == \"synthetic_data\"][:5]\n",
    "for x in examples:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b949b9",
   "metadata": {},
   "source": [
    "##### Dropping the `score` column\n",
    "* Quality score ranging from 0.0 to 10.0. This randomly generated value is a byproduct of the dataset processing pipeline and is not specifically relevant to the punctuation restoration task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8373e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping \"score\" column\n",
    "# score: Quality score ranging from 0.0 to 10.0. This randomly generated value is a byproduct of the dataset processing pipeline and is not specifically relevant to the punctuation restoration task.\n",
    "\n",
    "if \"score\" in df.column_names:\n",
    "    df = df.remove_columns(column_names=\"score\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92136d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = list(df[\"score\"])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(scores)\n",
    "# plt.xlabel(\"Score\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Score Distribution\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# word_lens = [\n",
    "#     sum(len(turn[\"value\"].split()) for turn in conv)\n",
    "#     for conv in df[\"conversations\"]\n",
    "# ]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(word_lens)\n",
    "# plt.xlabel(\"Total Words per Conversation\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Conversation Length (Words)\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# human_conv_len = [\n",
    "#     len(conv[0][\"value\"].split())\n",
    "#     for conv in df[\"conversations\"]\n",
    "# ]\n",
    "\n",
    "# human_conv_len = np.array(human_conv_len)\n",
    "# human_conv_len = np.sort(human_conv_len)\n",
    "# print(human_conv_len)\n",
    "# human_conv_len.min(), human_conv_len.max(), human_conv_len.mean()\n",
    "\n",
    "\n",
    "# empty_human_indices = [\n",
    "#     i for i, conv in enumerate(df[\"conversations\"])\n",
    "#     if len(conv[0][\"value\"].split()) <= 0\n",
    "# ]\n",
    "\n",
    "# print(\"Number of empty human inputs:\", len(empty_human_indices))\n",
    "# print(\"Indices of empty human inputs:\", empty_human_indices)\n",
    "\n",
    "# print(df[empty_human_indices[:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c27a39",
   "metadata": {},
   "source": [
    "##### Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7bd5826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bd_news_data', 'synthetic_data', 'hqtts_data', 'non_verbal_data']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique source\n",
    "df.unique(\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2edb63c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'synthetic_data': 1110,\n",
       "         'bd_news_data': 833,\n",
       "         'hqtts_data': 50,\n",
       "         'non_verbal_data': 7})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row counts from each source\n",
    "Counter(df[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0d475175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human',\n",
       "  'value': 'বাংলাদেশ প্রতিনিধিদলের একটি সূত্র অবশ্য প্রথম আলোকে জানায় তিস্তা নিয়ে কিছু বলার সময় এখনো আসেনি এ নিয়ে তাড়াহুড়োও নেই ভারতের আশ্বাসে আমরা সন্তুষ্ট মমতা বন্দ্যোপাধ্যায়ের ওপরেও আমাদের ভরসা আছে আমরা জানি ঠিক সময়েই এই বোঝাপড়া হয়ে যাবে চার দেশীয় যান চলাচল চুক্তি বিবিআইএন নিয়েও দুই পররাষ্ট্রসচিব বিস্তারিত আলোচনা করেছেন'},\n",
       " {'from': 'gpt',\n",
       "  'value': 'বাংলাদেশ প্রতিনিধিদলের একটি সূত্র অবশ্য প্রথম আলোকে জানায়, তিস্তা নিয়ে কিছু বলার সময় এখনো আসেনি। এ নিয়ে তাড়াহুড়োও নেই। ভারতের আশ্বাসে আমরা সন্তুষ্ট। মমতা বন্দ্যোপাধ্যায়ের ওপরেও আমাদের ভরসা আছে। আমরা জানি ঠিক সময়েই এই বোঝাপড়া হয়ে যাবে, চার দেশীয় যান চলাচল চুক্তি বিবিআইএন নিয়েও দুই পররাষ্ট্রসচিব বিস্তারিত আলোচনা করেছেন।'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row's \"conversation\" column\n",
    "df[\"conversations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b803e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entry in each conversation\n",
    "# must be equal to 2\n",
    "assert all(len(conv) == 2 for conv in df[\"conversations\"]), \"Must be exactly two entry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d8675bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt', 'human'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique conversation participants\n",
    "unique_participants = {\n",
    "    participant['from'] for conv in df[\"conversations\"]\n",
    "    for participant in conv\n",
    "}\n",
    "assert len(unique_participants) == 2, \"Must be only two differnt participants\"\n",
    "unique_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9851261",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# min, max, average conversation length\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m df[\u001b[33m\"\u001b[39m\u001b[33mconversations\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mconv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# min, max, average conversation length\n",
    "\n",
    "for conv in df[\"conversations\"]:\n",
    "    human = \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
